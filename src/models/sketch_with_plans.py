# sketch_with_plans.py

"""
Usage:
    PYTHONPATH=. python src/models/sketch_with_plans.py --groupname test --instruction_set toplevel_leaves
"""

import os
from os.path import abspath

import numpy as np
import torch
from torch import nn, optim
import torch.nn.functional as F
from torch.utils.data import DataLoader

from src import utils
from src.models.core import nn_utils
from src.models.core.train_nn import RUNS_PATH, TrainNN
from src.models.base.instruction_models import (
    ProgressionPairDataset,
    SketchWithPlansConditionEntireDrawingDataset,
    SketchWithPlansConditionSegmentsDataset,
    InstructionEncoderTransformer,
    LABELED_PROGRESSION_PAIRS_IDX2TOKEN_PATH
)
from src.models.base.stroke_models import (
    SketchRNNDecoderGMM
)
from src.models.sketch_rnn import SketchRNNModel
from src.models.sketch_rnn import HParams as SketchRNNHParams

USE_CUDA = torch.cuda.is_available()

class HParams(SketchRNNHParams):
    def __init__(self):
        super().__init__()
        self.instruction_set = 'toplevel'  # 'toplevel_leaves',  'stack'
        self.cond_instructions = 'initdec'  # 'initdec', 'decinputs'
        self.enc_dim = 512
        self.dec_dim = 512  # as is implemented right now, enc_dim == dec_dim when cond_instructions==initdec

        self.grad_accum_steps = 1

class SketchRNNWithTopLevelInstruction(SketchRNNModel):
    """"
    SketchRNN that also encodes and conditions on top-level instruction (i.e. instruction for entire
    drawing) generated by an instruction generation model.
    """
    def __init__(self, hp, save_dir):
        super().__init__(hp, save_dir)

        # Model
        vocab_size = len(utils.load_file(LABELED_PROGRESSION_PAIRS_IDX2TOKEN_PATH))
        self.text_embedding = nn.Embedding(vocab_size, hp.enc_dim)
        self.enc = InstructionEncoderTransformer(hp.enc_dim, hp.enc_num_layers, hp.dropout, use_categories=False)  # TODO: should this be a hparam
        dec_input_dim = 5 if (hp.cond_instructions == 'initdec') else (5 + hp.enc_dim)  # dec_inputs
        self.dec = SketchRNNDecoderGMM(dec_input_dim, hp.dec_dim, hp.M)  # Method 1 (see one_forward_pass, i.e. decinputs)

        self.models.extend([self.text_embedding, self.enc, self.dec])
        if USE_CUDA:
            for model in self.models:
                model.cuda()

        self.optimizers.append(optim.Adam(self.parameters(), hp.lr))

    def get_data_loader(self, dataset_split, batch_size, categories, shuffle=True):
        """
        Args:
            dataset_split (str): 'train', 'valid', 'test'
            batch_size (int)
            categories (str
            shuffle (bool)
        """
        if self.hp.instruction_set in ['initdec', 'decinputs']:
            ds = SketchWithPlansConditionEntireDrawingDataset(hp.dataset, dataset_split, instruction_set=self.hp.instruction_set)
            loader = DataLoader(ds, batch_size=batch_size, shuffle=shuffle,
                                collate_fn=ProgressionPairDataset.collate_fn)
        elif self.hp.instruction_set in ['stack']:
            ds = SketchWithPlansConditionSegmentsDataset(hp.dataset, dataset_split, instruction_set=self.hp.instruction_set)
            loader = DataLoader(ds, batch_size=1, shuffle=shuffle, collate_fn=SketchWithPlansConditionSegmentsDataset.collate_fn_bszone)

        return loader

    def preprocess_batch_from_data_loader(self, batch):
        """
        Convert tensors to cuda and convert to [len, bsz, ...] instead of [bsz, len, ...]
        """
        preprocessed = []
        for item in batch:
            if type(item) == torch.Tensor:
                item = nn_utils.move_to_cuda(item)
                if item.dim() > 1:
                    item.transpose_(0, 1)
            preprocessed.append(item)
        return preprocessed

    def one_forward_pass(self, batch):
        """
        Return loss and other items of interest for one forward pass

        Args:
            batch: tuple from DataLoaders

        Returns:
            dict where 'loss': float Tensor must exist
        """
        strokes, stroke_lens, texts, text_lens, text_indices, cats, cats_idx, urls = batch

        # Encode instructions
        hidden = self.enc(text_indices, text_lens, self.text_embedding,
                          category_embedding=None, categories=cats_idx)  # [bsz, dim]

        # Create inputs to decoder
        _, bsz, _ = strokes.size()
        sos = torch.stack([torch.Tensor([0, 0, 1, 0, 0])] * bsz).unsqueeze(0)  # start of sequence
        sos = nn_utils.move_to_cuda(sos)
        dec_inputs = torch.cat([sos, strokes], dim=0)  # add sos at the begining of the strokes; [max_len + 1, bsz, 5]

        # Method 1: concatenate instruction embedding to every time step
        if self.hp.cond_instructions == 'decinputs':
            hidden = hidden.unsqueeze(0)  #  [1, bsz, dim]
            hidden = hidden.repeat(dec_inputs.size(0), 1, 1)  # [max_len + 1, bsz, dim]
            dec_inputs = torch.cat([dec_inputs, hidden], dim=2)  # [max_len + 1, bsz, 5 + dim]
            pi, mu_x, mu_y, sigma_x, sigma_y, rho_xy, q, _, _ = self.dec(dec_inputs, output_all=True)

        # Method 2: initialize decoder's hidden state with instruction embedding
        elif self.hp.cond_instructions == 'initdec':
            hidden = hidden.unsqueeze(0)  #  [1, bsz, dim]
            hidden_cell = (hidden, hidden.clone())
            pi, mu_x, mu_y, sigma_x, sigma_y, rho_xy, q, _, _ = self.dec(dec_inputs, output_all=True, hidden_cell=hidden_cell)

        # Calculate losses
        mask, dx, dy, p = self.dec.make_target(strokes, stroke_lens, self.hp.M)

        loss = self.dec.reconstruction_loss(mask,
                                            dx, dy, p,
                                            pi, mu_x, mu_y, sigma_x, sigma_y, rho_xy,
                                            q)
        result = {'loss': loss, 'loss_R': loss}

        if ((loss != loss).any() or (loss == float('inf')).any() or (loss == float('-inf')).any()):
            raise Exception('Nan in SketchRNnDecoderGMMOnly forward pass')

        return result

    def generate_and_save(self, data_loader, epoch, n_gens=1, outputs_path=None):
        # TODO: need to overwrite this. SketchRNN's generate_and_save() unpacks a batch from
        # a dataset that returns 4 values. The SketchWithPlansDataset returns 8 values. The
        # encoding of the instructions is different too. Need to refactor that bit to work
        # with both.
        pass

if __name__ == "__main__":
    hp = HParams()
    hp, run_name, parser = utils.create_argparse_and_update_hp(hp)
    parser.add_argument('--groupname', default='debug', help='name of subdir to save runs')
    opt = parser.parse_args()
    nn_utils.setup_seeds()

    save_dir = os.path.join(RUNS_PATH, 'sketchwplans', opt.groupname, run_name)
    utils.save_run_data(save_dir, hp)

    model = None
    model = SketchRNNWithTopLevelInstruction(hp, save_dir)
    model.train_loop()
